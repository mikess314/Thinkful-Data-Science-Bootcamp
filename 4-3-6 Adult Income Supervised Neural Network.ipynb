{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise I'll build a series of MLPClassifiers using [this UCI dataset](https://archive.ics.uci.edu/ml/datasets/Adult) to predict based on census demographic data whether people were earning more than or less thatn $50K annually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
       "       'marital_status', 'occupation', 'relationship', 'race', 'sex',\n",
       "       'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
       "       'income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               object\n",
       "workclass         object\n",
       "fnlwgt            object\n",
       "education         object\n",
       "education_num     object\n",
       "marital_status    object\n",
       "occupation        object\n",
       "relationship      object\n",
       "race              object\n",
       "sex               object\n",
       "capital_gain       int64\n",
       "capital_loss       int64\n",
       "hours_per_week     int64\n",
       "native_country    object\n",
       "income            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like I have some data cleaning to do:\n",
    "\n",
    "- Convert Age to integer\n",
    "- Replace '?' with 'Unknown' in workclass, education, occupation\n",
    "- replace '#NAME?' with 'Unknown' in race, sex\n",
    "- replace '#NAME?' with '40' in age (the mean age, rounded)\n",
    "- impute most frequent for age\n",
    "- drop fnlwgt, education_num, native_country\n",
    "- create dummies for workclass, education, marital_status, occupation, relationship, race, sex\n",
    "\n",
    "income will be my target classifier with the model trying to predict if a person is making \"<=50K\" or \">50K\"\n",
    "\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White                 4021\n",
       "Black                  493\n",
       "#NAME?                 264\n",
       "Asian-Pac-Islander     145\n",
       "Amer-Indian-Eskimo      48\n",
       "Other                   29\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = df['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['income', 'fnlwgt', 'education_num', 'native_country'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'] = df['race'].replace('#NAME?','Unknown')\n",
    "df['age'] = df['age'].replace('#NAME?','40')\n",
    "df['sex'] = df['sex'].replace('#NAME?','Unknown')\n",
    "df['workclass'] = df['workclass'].replace('?','Unknown')\n",
    "df['education'] = df['education'].replace('?','Unknown')\n",
    "df['occupation'] = df['occupation'].replace('?','Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data=df, columns=['workclass', \n",
    "                                      'education', \n",
    "                                      'marital_status', \n",
    "                                      'occupation', \n",
    "                                      'relationship', \n",
    "                                      'race', \n",
    "                                      'sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'capital_gain', 'capital_loss', 'hours_per_week',\n",
       "       'workclass_Federal-gov', 'workclass_Local-gov', 'workclass_Private',\n",
       "       'workclass_Self-emp-inc', 'workclass_Self-emp-not-inc',\n",
       "       'workclass_State-gov', 'workclass_Unknown', 'workclass_Without-pay',\n",
       "       'education_10th', 'education_11th', 'education_12th',\n",
       "       'education_1st-4th', 'education_5th-6th', 'education_7th-8th',\n",
       "       'education_9th', 'education_Assoc-acdm', 'education_Assoc-voc',\n",
       "       'education_Bachelors', 'education_Doctorate', 'education_HS-grad',\n",
       "       'education_Masters', 'education_Preschool', 'education_Prof-school',\n",
       "       'education_Some-college', 'education_Unknown',\n",
       "       'marital_status_Divorced', 'marital_status_Married-AF-spouse',\n",
       "       'marital_status_Married-civ-spouse',\n",
       "       'marital_status_Married-spouse-absent', 'marital_status_Never-married',\n",
       "       'marital_status_Separated', 'marital_status_Widowed',\n",
       "       'occupation_Adm-clerical', 'occupation_Armed-Forces',\n",
       "       'occupation_Craft-repair', 'occupation_Exec-managerial',\n",
       "       'occupation_Farming-fishing', 'occupation_Handlers-cleaners',\n",
       "       'occupation_Machine-op-inspct', 'occupation_Other-service',\n",
       "       'occupation_Priv-house-serv', 'occupation_Prof-specialty',\n",
       "       'occupation_Protective-serv', 'occupation_Sales',\n",
       "       'occupation_Tech-support', 'occupation_Transport-moving',\n",
       "       'occupation_Unknown', 'relationship_Husband',\n",
       "       'relationship_Not-in-family', 'relationship_Other-relative',\n",
       "       'relationship_Own-child', 'relationship_Unmarried', 'relationship_Wife',\n",
       "       'race_Amer-Indian-Eskimo', 'race_Asian-Pac-Islander', 'race_Black',\n",
       "       'race_Other', 'race_Unknown', 'race_White', 'sex_Female', 'sex_Male',\n",
       "       'sex_Unknown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                             int32\n",
       "capital_gain                    int64\n",
       "capital_loss                    int64\n",
       "hours_per_week                  int64\n",
       "workclass_Federal-gov           uint8\n",
       "workclass_Local-gov             uint8\n",
       "workclass_Private               uint8\n",
       "workclass_Self-emp-inc          uint8\n",
       "workclass_Self-emp-not-inc      uint8\n",
       "workclass_State-gov             uint8\n",
       "workclass_Unknown               uint8\n",
       "workclass_Without-pay           uint8\n",
       "education_10th                  uint8\n",
       "education_11th                  uint8\n",
       "education_12th                  uint8\n",
       "education_1st-4th               uint8\n",
       "education_5th-6th               uint8\n",
       "education_7th-8th               uint8\n",
       "education_9th                   uint8\n",
       "education_Assoc-acdm            uint8\n",
       "education_Assoc-voc             uint8\n",
       "education_Bachelors             uint8\n",
       "education_Doctorate             uint8\n",
       "education_HS-grad               uint8\n",
       "education_Masters               uint8\n",
       "education_Preschool             uint8\n",
       "education_Prof-school           uint8\n",
       "education_Some-college          uint8\n",
       "education_Unknown               uint8\n",
       "marital_status_Divorced         uint8\n",
       "                                ...  \n",
       "occupation_Adm-clerical         uint8\n",
       "occupation_Armed-Forces         uint8\n",
       "occupation_Craft-repair         uint8\n",
       "occupation_Exec-managerial      uint8\n",
       "occupation_Farming-fishing      uint8\n",
       "occupation_Handlers-cleaners    uint8\n",
       "occupation_Machine-op-inspct    uint8\n",
       "occupation_Other-service        uint8\n",
       "occupation_Priv-house-serv      uint8\n",
       "occupation_Prof-specialty       uint8\n",
       "occupation_Protective-serv      uint8\n",
       "occupation_Sales                uint8\n",
       "occupation_Tech-support         uint8\n",
       "occupation_Transport-moving     uint8\n",
       "occupation_Unknown              uint8\n",
       "relationship_Husband            uint8\n",
       "relationship_Not-in-family      uint8\n",
       "relationship_Other-relative     uint8\n",
       "relationship_Own-child          uint8\n",
       "relationship_Unmarried          uint8\n",
       "relationship_Wife               uint8\n",
       "race_Amer-Indian-Eskimo         uint8\n",
       "race_Asian-Pac-Islander         uint8\n",
       "race_Black                      uint8\n",
       "race_Other                      uint8\n",
       "race_Unknown                    uint8\n",
       "race_White                      uint8\n",
       "sex_Female                      uint8\n",
       "sex_Male                        uint8\n",
       "sex_Unknown                     uint8\n",
       "Length: 66, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Notes and Model Build\n",
    "\n",
    "The question of my unknown values is a consideration worth discussing. Should I replace those placeholders with NaN and then dropna? Perhaps. And perhaps I will after I've run the models for this neural network.\n",
    "\n",
    "The number of features created might be a problem for computational cost. If it takes too long I'll drop a feature, starting with the one with the most values (native_country) and try again. \n",
    "\n",
    "I split off my y target early on because the classifier format was proving problematic for my preprocessing. After preprocessing both df and y still have 5000 observations. If the model still doesn't like the characters, I'll go back and replace them with text strings.\n",
    "\n",
    "To start off, I'll build a models with only a small number of perceptrons, just to prove it works quickly. I don't expect good results from that. Then I'll add more perceptrons and then layers of perceptrons. Once built I'll tune the model parameters as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 66)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(50,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50,))\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.805"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78606965, 0.76      , 0.77      , 0.795     , 0.76884422])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp, X_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. I have to say I wasn't expecting a single layer, 50 perceptron model to yield such a high score. And it ran very fast. So now I'll rerun this model for the following layer sizes:\n",
    "\n",
    "- (1000,)\n",
    "- (100, 100)\n",
    "- (1000, 1000)\n",
    "- (100, 100, 100)\n",
    "- (1000, 1000, 1000)\n",
    "\n",
    "If as it gets thicker and thicker the time to run the model gets too long I'll remove that layer size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1000,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(1000,))\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.799"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80099502, 0.77      , 0.765     , 0.795     , 0.79396985])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp, X_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100))\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.789"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76119403, 0.735     , 0.775     , 0.77      , 0.47738693])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp, X_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1000, 1000), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(1000,1000))\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.757"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76119403, 0.75      , 0.75      , 0.265     , 0.77889447])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp, X_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100,100))\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74129353, 0.735     , 0.75      , 0.775     , 0.65326633])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp, X_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp = MLPClassifier(hidden_layer_sizes=(1000,1000,1000))\n",
    "# mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(mlp, X_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our scores and cross validations. The increase of hidden layers did not seem to have any significant positive impact on the model's performance. In fact, the more layers, the worse they seemed to perform. The single layer, 1000 perceptron model performed the best with a score of 79.9% and cross validation scores ranging from 0.800, 0.770, 0.765, 0.795, 0.793 (a range of only 3.5%) indicating that the model is not overfit. Surprising really that the single layer, 50 perceptron model actually outperformed this. But I like the consistency of the folds here. \n",
    "\n",
    "Now I'll re-run the model for a single 100 perceptron layer and make some changes to the parameters. Models that perform in an uninteresting way or error out I'll delete and continue on. Otherwise below I'll add in models that are worth talking about. Note that as a default I am looking for scores that are better than 79.9% (or really low so that I can research to understand why)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100, ), \n",
    "                    activation='relu', # {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default ‘relu’\n",
    "                    solver='adam', # {‘lbfgs’, ‘sgd’, ‘adam’}, default ‘adam’\n",
    "                    alpha=0.1, # float, optional, default 0.0001\n",
    "                    batch_size='auto', # int, optional, default ‘auto’ (Must not be using solver='lbfgs')\n",
    "                    learning_rate='constant', # {‘constant’, ‘invscaling’, ‘adaptive’}, default ‘constant’\n",
    "                    learning_rate_init=0.001, # double, optional, default 0.001\n",
    "                    power_t=0.5, # double, optional, default 0.5 (learning_rate = ‘invscaling’. solver=’sgd’.)\n",
    "                    max_iter=200, # int, optional, default 200\n",
    "                    shuffle=True, # bool, optional, default True\n",
    "                    random_state=None, # int, RandomState instance or None, optional, default None\n",
    "                    tol=0.0001, # float, optional, default 1e-4\n",
    "                    verbose=False, # bool, optional, default False (I like this. I like more info)\n",
    "                    warm_start=False, # bool, optional, default False \n",
    "                    momentum=0.9, # float, default 0.9 (solver=’sgd’)\n",
    "                    nesterovs_momentum=True, # boolean, default True (must have solver=’sgd’ and momentum > 0)\n",
    "                    early_stopping=False, # bool, default False (Only effective when solver=’sgd’ or ‘adam’)\n",
    "                    validation_fraction=0.1, # float, optional, default 0.1 (Only used if early_stopping is True)\n",
    "                    beta_1=0.9, # float, optional, default 0.9 (Only used when solver=’adam’)\n",
    "                    beta_2=0.999, # float,  optional, default 0.999 (Only used when solver=’adam’)\n",
    "                    epsilon=1e-08) #  float, optional, default 1e-8 (Only used when solver=’adam’)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.833"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High score: 81.1 but changes each time so margin of error dictates that no changes produce significantly improved results.\n",
    "\n",
    "Slight uptick in average model score by increasing alpha to 0.1 from 0.0001 default. So increasing L2 (Ridge Regulation) penalty. Otherwise the results were either below my best results but still above 70% generally, or just errored out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76119403, 0.755     , 0.79      , 0.75      , 0.76884422])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp, X_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
