{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data again. Keep air quality data, drop the index column\n",
    "# and any missing data columns.\n",
    "df = pd.read_csv(\n",
    "    'https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/Default.csv'\n",
    ").iloc[:,1:].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode strings to numeric.\n",
    "df['default'] = np.where(df['default']=='Yes', 1, 0)\n",
    "df['student'] = np.where(df['student']=='Yes', 1, 0)\n",
    "names = df.columns\n",
    "df = pd.DataFrame(preprocessing.scale(df), columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training and test sizes.\n",
    "trainsize = int(df.shape[0] / 2)\n",
    "df_test = df.iloc[trainsize:, :].copy()\n",
    "df_train = df.iloc[:trainsize, :].copy()\n",
    "\n",
    "Y_train = df_train['income'].values.reshape(-1, 1)\n",
    "X_train = df_train.loc[:, ~(df_train.columns).isin(['income'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some new features to capture potential quadratic and cubic\n",
    "# relationships between solar radiation and day or temperature.\n",
    "df_train['balance_student'] = df_train['balance'] * df_train['student']\n",
    "df_train['balance_default'] = df_train['balance'] * df_train['default']\n",
    "df_train['student_default'] = df_train['student'] * df_train['default']\n",
    "df_train['balance_sqrt'] = (df_train['balance'] + 100) ** .5\n",
    "df_train['balance2'] = (df_train['balance'] + 100) ** 2\n",
    "df_train['balance3'] = (df_train['balance'] + 100) ** 3\n",
    "\n",
    "X_train2 = df_train.loc[:, ~(df_train.columns).isin(['income'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the simpler model with smaller coefficients.\n",
    "Y_test = df_test['income'].values.reshape(-1, 1)\n",
    "X_test = df_test.loc[:, ~(df_test.columns).isin(['income'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the more complex model with larger coefficients.\n",
    "df_test['balance_student'] = df_test['balance'] * df_test['student']\n",
    "df_test['balance_default'] = df_test['balance'] * df_test['default']\n",
    "df_test['student_default'] = df_test['student'] * df_test['default']\n",
    "df_test['balance_sqrt'] = (df_test['balance'] + 100) ** .5\n",
    "df_test['balance2'] = (df_test['balance'] + 100) ** 2\n",
    "df_test['balance3'] = (df_test['balance'] + 100) ** 3\n",
    "X_test2 = df_test.loc[:, ~(df_test.columns).isin(['income'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² for the model with few features:\n",
      "0.450062579301185\n",
      "\n",
      "Parameter estimates for the model with few features:\n",
      "[-0.         -0.40657726 -0.          0.00114596]\n"
     ]
    }
   ],
   "source": [
    "# Small number of parameters.\n",
    "lass = linear_model.Lasso(alpha=.35)\n",
    "lassfit = lass.fit(X_train, Y_train)\n",
    "print('R² for the model with few features:')\n",
    "print(lass.score(X_train, Y_train))\n",
    "origparams = np.append(lassfit.coef_, lassfit.intercept_)\n",
    "print('\\nParameter estimates for the model with few features:')\n",
    "print(origparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R² for the model with many features:\n",
      "0.44363376712897096\n",
      "\n",
      "Parameter estimates for the model with many features:\n",
      "[ 0.00000000e+00 -3.89351238e-01  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00 -2.77688887e-04\n",
      " -7.09158792e-07  3.48711577e+00]\n"
     ]
    }
   ],
   "source": [
    "# Large number of parameters.\n",
    "lassBig = linear_model.Lasso(alpha=.35)\n",
    "lassBig.fit(X_train2, Y_train)\n",
    "print('\\nR² for the model with many features:')\n",
    "print(lassBig.score(X_train2, Y_train))\n",
    "origparams = np.append(lassBig.coef_, lassBig.intercept_)\n",
    "print('\\nParameter estimates for the model with many features:')\n",
    "print(origparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44553225151184195\n",
      "0.4380466345914476\n"
     ]
    }
   ],
   "source": [
    "print(lass.score(X_test, Y_test))\n",
    "\n",
    "print(lassBig.score(X_test2, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization parameter: Lasso\n",
    "\n",
    "The $\\lambda$ for lasso can var between 0 (no penalty, acts like OLS) and infinity.  If $\\lambda$ is too large, all parameters will be set to zero.  \n",
    "\n",
    "Create a plot below of how $R^2$ varies across different values of $\\lambda$ for ridge and lasso regression. Use logic and code similar to the ridge regression demonstration above, and base your plot on the X_train2 feature set.\n",
    "\n",
    "Do lasso and ridge yield the same $R^2$ for a given lambda value?\n",
    "\n",
    "Submit your work and discuss the results with your mentor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared simple model, range of alpha: 10 to 0.01\n",
      "R2 Score for alpha 10\n",
      "0.5738739164402877\n",
      "[ 1.36988466e-02 -7.57859433e-01 -3.25298557e-04]\n",
      "\n",
      "\n",
      "R2 Score for alpha 5\n",
      "0.5738757447223357\n",
      "[ 1.36831110e-02 -7.58661482e-01 -1.42519678e-04]\n",
      "\n",
      "\n",
      "R2 Score for alpha 0.5\n",
      "0.573876349838232\n",
      "[ 1.36687345e-02 -7.59384859e-01  2.27104494e-05]\n",
      "\n",
      "\n",
      "R2 Score for alpha 0.05\n",
      "0.5738763559016591\n",
      "[ 1.36672856e-02 -7.59457276e-01  3.92715937e-05]\n",
      "\n",
      "\n",
      "R2 Score for alpha 0.01\n",
      "0.5738763559604679\n",
      "[ 1.36671568e-02 -7.59463714e-01  4.07440315e-05]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RIDGE REGRESSIONS \n",
    "print('\\nR-squared simple model, range of alpha: 10 to 0.01')\n",
    "alphas = [10, 5, .5, .05, .01]\n",
    "\n",
    "for item in alphas:\n",
    "    ridgeregr = linear_model.Ridge(alpha=item, fit_intercept=False) \n",
    "    ridgeregr.fit(X_train, Y_train)\n",
    "    print(('R2 Score for alpha {}').format(item))\n",
    "    print(ridgeregr.score(X_train, Y_train))\n",
    "    origparams = ridgeregr.coef_[0]\n",
    "    print(origparams)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared complex model, range of alpha: 10 to 0.01\n",
      "R2 Score for alpha 10\n",
      "0.5739464289613794\n",
      "[-2.18345205e-03 -7.57156891e-01  4.77049994e-02 -3.66908529e-03\n",
      "  9.52109450e-03 -3.78154074e-03 -4.47224226e-03  4.83414405e-04\n",
      " -4.79227772e-06]\n",
      "\n",
      "\n",
      "R2 Score for alpha 5\n",
      "0.5739545553547272\n",
      "[-2.75035289e-03 -7.58006613e-01  8.20932503e-02 -3.25822468e-03\n",
      "  1.00153856e-02 -3.90435470e-03 -7.69484415e-03  8.32936629e-04\n",
      " -8.25484783e-06]\n",
      "\n",
      "\n",
      "R2 Score for alpha 0.5\n",
      "0.573971000824615\n",
      "[-4.78907258e-03 -7.58839870e-01  2.29990088e-01 -2.00381206e-03\n",
      "  1.19925826e-02 -4.30877426e-03 -2.14959225e-02  2.34255200e-03\n",
      " -2.32109719e-05]\n",
      "\n",
      "\n",
      "R2 Score for alpha 0.05\n",
      "0.5739723222459411\n",
      "[-5.45589463e-03 -7.58943559e-01  2.80310564e-01 -1.61027419e-03\n",
      "  1.26546909e-02 -4.43823944e-03 -2.54469442e-02  2.85474057e-03\n",
      " -2.82926495e-05]\n",
      "\n",
      "\n",
      "R2 Score for alpha 0.01\n",
      "0.5739723413444707\n",
      "[-5.52924236e-03 -7.58953395e-01  2.86176923e-01 -1.56712339e-03\n",
      "  1.27276745e-02 -4.45246087e-03 -2.25713517e-02  2.90612076e-03\n",
      " -2.88351301e-05]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\linalg\\basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 9.244323806585906e-17 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\linalg\\basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 9.12542022922663e-18 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\linalg\\basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 1.8225496232404727e-18 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#RIDGE REGRESSIONS WITH COMPLEX MODEL\n",
    "\n",
    "print('\\nR-squared complex model, range of alpha: 10 to 0.01')\n",
    "alphas = [10, 5, .5, .05, .01]\n",
    "\n",
    "for item in alphas:\n",
    "    ridgeregr = linear_model.Ridge(alpha=item, fit_intercept=False) \n",
    "    ridgeregr.fit(X_train2, Y_train)\n",
    "    print(('R2 Score for alpha {}').format(item))\n",
    "    print(ridgeregr.score(X_train2, Y_train))\n",
    "    origparams = ridgeregr.coef_[0]\n",
    "    print(origparams)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virtually zero change in R2 from simple to complex and without regard for the alpha chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared simple model, range of alpha: .01 to 1\n",
      "R2 Score for alpha 0.01\n",
      "0.5736726279636906\n",
      "[ 0.00369631 -0.7489349   0.         -0.00129277]\n",
      "\n",
      "\n",
      "R2 Score for alpha 0.05\n",
      "0.5711587609212556\n",
      "[ 0.         -0.70850468 -0.         -0.00097388]\n",
      "\n",
      "\n",
      "R2 Score for alpha 0.35\n",
      "0.450062579301185\n",
      "[-0.         -0.40657726 -0.          0.00114596]\n",
      "\n",
      "\n",
      "R2 Score for alpha 0.75\n",
      "0.006043246694259263\n",
      "[-0.         -0.00400737 -0.          0.00397242]\n",
      "\n",
      "\n",
      "R2 Score for alpha 1\n",
      "0.0\n",
      "[-0.         -0.         -0.          0.00400056]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LASSO REGRESSIONS WITH SIMPLE MODEL\n",
    "print('\\nR-squared simple model, range of alpha: .01 to 1')\n",
    "alphas = [.01, .05, .35, .75, 1]\n",
    "\n",
    "for item in alphas:\n",
    "    lass = linear_model.Lasso(alpha=item)\n",
    "    lassfit = lass.fit(X_train, Y_train)\n",
    "    print(('R2 Score for alpha {}').format(item))\n",
    "    print(lass.score(X_train, Y_train))\n",
    "    origparams = np.append(lassfit.coef_, lassfit.intercept_)\n",
    "    print(origparams)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared complex model, range of alpha: .01 to 1\n",
      "R2 Score for alpha 0.01\n",
      "0.5737681044618193\n",
      "[ 0.00000000e+00 -7.49175475e-01  0.00000000e+00 -0.00000000e+00\n",
      "  4.64868670e-03 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -1.45217294e-09 -1.52452354e-03]\n",
      "\n",
      "\n",
      "R2 Score for alpha 0.05\n",
      "0.5710532985531875\n",
      "[ 0.00000000e+00 -7.07044072e-01 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.89911443e-05\n",
      " -2.44078084e-08  3.13333305e-01]\n",
      "\n",
      "\n",
      "R2 Score for alpha 0.35\n",
      "0.44363376712897096\n",
      "[ 0.00000000e+00 -3.89351238e-01  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00 -2.77688887e-04\n",
      " -7.09158792e-07  3.48711577e+00]\n",
      "\n",
      "\n",
      "R2 Score for alpha 0.75\n",
      "0.026834134834571755\n",
      "[ 0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -5.42660058e-06  5.43077199e+00]\n",
      "\n",
      "\n",
      "R2 Score for alpha 1\n",
      "0.026834134351719777\n",
      "[ 0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -5.42632541e-06  5.43049680e+00]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LASSO REGRESSIONS WITH COMPLEX MODEL\n",
    "print('\\nR-squared complex model, range of alpha: .01 to 1')\n",
    "\n",
    "alphas = [.01, .05, .35, .75, 1]\n",
    "\n",
    "for item in alphas:\n",
    "    lass = linear_model.Lasso(alpha=item)\n",
    "    lassfit = lass.fit(X_train2, Y_train)\n",
    "    print(('R2 Score for alpha {}').format(item))\n",
    "    print(lass.score(X_train2, Y_train))\n",
    "    origparams = np.append(lassfit.coef_, lassfit.intercept_)\n",
    "    print(origparams)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see as expected that Ridge and LASSO respond very differently for various alpha levels. The LASSO regularization with alpha .01 is very similar for simple and complex models. This is likely the result of the zeroing of most of the added features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
